{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNMWIViejPs+iXPeodDp7pX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/michalrylko/decision-latency/blob/main/00_data_extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0. Decision Latency Analytics - Project Overview\n",
        "## Apache Airflow Pull Requests Case Study\n",
        "\n",
        "This project analyzes **decision-making latency** using real-world data from\n",
        "GitHub Pull Requests (PRs).\n",
        "\n",
        "A Pull Request is treated as a proxy for a **decision process**:\n",
        "- a proposal is submitted\n",
        "- reviewers evaluate the change\n",
        "- a final decision is made (merge or close)\n",
        "\n",
        "This notebook covers **Stage 0: Data Extraction**.\n",
        "Subsequent stages will focus on:\n",
        "- exploratory data analysis (EDA)\n",
        "- feature engineering\n",
        "- predictive modeling\n",
        "- decision design recommendations\n"
      ],
      "metadata": {
        "id": "33AvDeOWtBAQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Environment Setup & GitHub API Access\n",
        "\n",
        "This section:\n",
        "- installs required libraries\n",
        "- sets up the Python environment\n",
        "- configures access to the GitHub API\n",
        "\n",
        "Authentication is handled via an environment variable (`GITHUB_TOKEN`)\n",
        "configured outside the notebook (e.g. Colab Secrets)."
      ],
      "metadata": {
        "id": "OGmEaRxZtFGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install pandas requests\n",
        "\n",
        "import os\n",
        "import time\n",
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "# GitHub token is expected to be available as an environment variable\n",
        "GITHUB_TOKEN = os.getenv(\"GITHUB_TOKEN\")\n",
        "\n",
        "import os\n",
        "\n",
        "def load_github_token():\n",
        "    # 1) Standard: environment variable\n",
        "    token = os.getenv(\"GITHUB_TOKEN\")\n",
        "    if token:\n",
        "        return token\n",
        "\n",
        "    # 2) Colab Secrets fallback\n",
        "    try:\n",
        "        from google.colab import userdata  # type: ignore\n",
        "        return userdata.get(\"GITHUB_TOKEN\")\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "GITHUB_TOKEN = load_github_token()\n",
        "print(\"GitHub token loaded:\", bool(GITHUB_TOKEN))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CK58UmTVsUbY",
        "outputId": "5d78ddc2-42ba-43af-fa81-9e9c3fc7f695"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GitHub token loaded: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the token is correctly configured, authenticated requests will benefit from\n",
        "a significantly higher rate limit (~5000 requests/hour)."
      ],
      "metadata": {
        "id": "ii6lqFY7t8IX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Repository Configuration\n",
        "\n",
        "We extract data from the public GitHub repository:\n",
        "\n",
        "- Repository: `apache/airflow`\n",
        "- Data source: GitHub Pull Requests API\n",
        "- Scope: closed Pull Requests only"
      ],
      "metadata": {
        "id": "eQavgmxcuEMG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "REPO_OWNER = \"apache\"\n",
        "REPO_NAME = \"airflow\"\n",
        "\n",
        "PER_PAGE = 100\n",
        "MAX_PAGES = 100        # ~10 000 PRs\n",
        "REQUEST_DELAY = 0.2 # seconds between API calls\n",
        "\n",
        "headers = {\"Accept\": \"application/vnd.github+json\"}\n",
        "if GITHUB_TOKEN:\n",
        "    headers[\"Authorization\"] = f\"Bearer {GITHUB_TOKEN}\"\n",
        "\n",
        "session = requests.Session()\n",
        "session.headers.update(headers)\n"
      ],
      "metadata": {
        "id": "mmmhShG7sXVu"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. GitHub API Helper\n",
        "\n",
        "A helper function is used to:\n",
        "- handle temporary API failures\n",
        "- retry requests affected by rate limits\n",
        "- keep the extraction pipeline robust\n"
      ],
      "metadata": {
        "id": "-BDgAU0lvwpO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_json(url, params=None, retries=3):\n",
        "    for attempt in range(retries):\n",
        "        response = session.get(url, params=params)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            return response.json()\n",
        "\n",
        "        if response.status_code in (403, 429, 502, 503, 504):\n",
        "            wait_time = 2 ** attempt\n",
        "            time.sleep(wait_time)\n",
        "            continue\n",
        "\n",
        "        print(f\"API error {response.status_code}: {response.text[:200]}\")\n",
        "        return None\n",
        "\n",
        "    return None\n"
      ],
      "metadata": {
        "id": "b_txmwYsvwVh"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Pull Request Collection\n",
        "\n",
        "In this step we:\n",
        "1. Fetch a lightweight list of closed Pull Requests\n",
        "2. Fetch detailed metadata for each Pull Request\n",
        "\n",
        "This includes information such as:\n",
        "- comments and review comments\n",
        "- number of commits\n",
        "- files changed\n",
        "- lines added and deleted\n"
      ],
      "metadata": {
        "id": "PNRezwzav5kD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pull_requests_light = []\n",
        "\n",
        "# Step 1: lightweight PR list\n",
        "for page in range(1, MAX_PAGES + 1):\n",
        "    url = f\"https://api.github.com/repos/{REPO_OWNER}/{REPO_NAME}/pulls\"\n",
        "    params = {\n",
        "        \"state\": \"closed\",\n",
        "        \"per_page\": PER_PAGE,\n",
        "        \"page\": page\n",
        "    }\n",
        "\n",
        "    data = fetch_json(url, params=params)\n",
        "    if not data:\n",
        "        break\n",
        "\n",
        "    for pr in data:\n",
        "        pull_requests_light.append({\n",
        "            \"pr_number\": pr.get(\"number\"),\n",
        "            \"pr_id\": pr.get(\"id\"),\n",
        "            \"repository\": f\"{REPO_OWNER}/{REPO_NAME}\",\n",
        "            \"created_at\": pr.get(\"created_at\"),\n",
        "            \"closed_at\": pr.get(\"closed_at\"),\n",
        "            \"merged_at\": pr.get(\"merged_at\"),\n",
        "            \"author\": (pr.get(\"user\") or {}).get(\"login\"),\n",
        "            \"labels\": [label.get(\"name\") for label in pr.get(\"labels\", [])]\n",
        "        })\n",
        "\n",
        "    time.sleep(REQUEST_DELAY)\n",
        "\n",
        "# Step 2: detailed metadata\n",
        "pull_requests_full = []\n",
        "\n",
        "for pr in pull_requests_light:\n",
        "    pr_number = pr[\"pr_number\"]\n",
        "    if pr_number is None:\n",
        "        continue\n",
        "\n",
        "    detail_url = (\n",
        "        f\"https://api.github.com/repos/\"\n",
        "        f\"{REPO_OWNER}/{REPO_NAME}/pulls/{pr_number}\"\n",
        "    )\n",
        "\n",
        "    details = fetch_json(detail_url)\n",
        "    if details is None:\n",
        "        continue\n",
        "\n",
        "    pull_requests_full.append({\n",
        "        **pr,\n",
        "        \"merged\": details.get(\"merged_at\") is not None,\n",
        "        \"comments_count\": details.get(\"comments\"),\n",
        "        \"review_comments_count\": details.get(\"review_comments\"),\n",
        "        \"commit_count\": details.get(\"commits\"),\n",
        "        \"changed_files_count\": details.get(\"changed_files\"),\n",
        "        \"additions\": details.get(\"additions\"),\n",
        "        \"deletions\": details.get(\"deletions\")\n",
        "    })\n",
        "\n",
        "    time.sleep(REQUEST_DELAY)\n"
      ],
      "metadata": {
        "id": "j_t8-ldPv5-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Dataset Construction and Decision Latency Metric\n",
        "\n",
        "Decision latency is defined as the number of days between:\n",
        "- Pull Request creation\n",
        "- Pull Request closure (merge or close)\n",
        "**bold text**"
      ],
      "metadata": {
        "id": "Lp21z4sHwBKZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df = pd.DataFrame(pull_requests_full)\n",
        "\n",
        "df[\"created_at\"] = pd.to_datetime(df[\"created_at\"], errors=\"coerce\")\n",
        "df[\"closed_at\"] = pd.to_datetime(df[\"closed_at\"], errors=\"coerce\")\n",
        "\n",
        "df[\"decision_latency_days\"] = (\n",
        "    df[\"closed_at\"] - df[\"created_at\"]\n",
        ").dt.days\n",
        "\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "3XnUfnMwwBiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Data Export & Validation\n",
        "\n",
        "The dataset is saved locally to avoid repeated API calls\n",
        "in subsequent analysis stages."
      ],
      "metadata": {
        "id": "v7cxFdfYwB2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_file = \"apache_airflow_pull_requests_raw.csv\"\n",
        "df.to_csv(output_file, index=False)\n",
        "\n",
        "print(\"Dataset saved:\", output_file)\n",
        "df[\"decision_latency_days\"].describe()\n"
      ],
      "metadata": {
        "id": "Dgnc5yDWwCF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Summary & Next Steps\n",
        "\n",
        "This notebook completed **Stage 0: Data Extraction**.\n",
        "\n",
        "Next stages:\n",
        "- Exploratory Data Analysis (EDA)\n",
        "- Feature engineering\n",
        "- Predictive modeling\n",
        "- Decision design recommendations\n"
      ],
      "metadata": {
        "id": "NueKIkC7yF74"
      }
    }
  ]
}